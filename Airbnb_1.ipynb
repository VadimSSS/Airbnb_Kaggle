{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this competition Airbnb challenged Kagglers to predict in which country a new user will make his or her first booking. \n",
    "https://www.kaggle.com/c/airbnb-recruiting-new-user-bookings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "test = pd.read_csv('test_users.csv', header=0, parse_dates=[1,2,3])\n",
    "train = pd.read_csv('train_users_2.csv', header=0, parse_dates=[1,2,3])\n",
    "sessions = pd.read_csv(\"sessions.csv\", encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date_account_created</th>\n",
       "      <th>timestamp_first_active</th>\n",
       "      <th>date_first_booking</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>signup_method</th>\n",
       "      <th>signup_flow</th>\n",
       "      <th>language</th>\n",
       "      <th>affiliate_channel</th>\n",
       "      <th>affiliate_provider</th>\n",
       "      <th>first_affiliate_tracked</th>\n",
       "      <th>signup_app</th>\n",
       "      <th>first_device_type</th>\n",
       "      <th>first_browser</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5uwns89zht</td>\n",
       "      <td>2014-07-01</td>\n",
       "      <td>2014-07-01 00:00:06</td>\n",
       "      <td>NaT</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>35.0</td>\n",
       "      <td>facebook</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>direct</td>\n",
       "      <td>direct</td>\n",
       "      <td>untracked</td>\n",
       "      <td>Moweb</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Mobile Safari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jtl0dijy2j</td>\n",
       "      <td>2014-07-01</td>\n",
       "      <td>2014-07-01 00:00:51</td>\n",
       "      <td>NaT</td>\n",
       "      <td>-unknown-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>direct</td>\n",
       "      <td>direct</td>\n",
       "      <td>untracked</td>\n",
       "      <td>Moweb</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Mobile Safari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xx0ulgorjt</td>\n",
       "      <td>2014-07-01</td>\n",
       "      <td>2014-07-01 00:01:48</td>\n",
       "      <td>NaT</td>\n",
       "      <td>-unknown-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>direct</td>\n",
       "      <td>direct</td>\n",
       "      <td>linked</td>\n",
       "      <td>Web</td>\n",
       "      <td>Windows Desktop</td>\n",
       "      <td>Chrome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6c6puo6ix0</td>\n",
       "      <td>2014-07-01</td>\n",
       "      <td>2014-07-01 00:02:15</td>\n",
       "      <td>NaT</td>\n",
       "      <td>-unknown-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>direct</td>\n",
       "      <td>direct</td>\n",
       "      <td>linked</td>\n",
       "      <td>Web</td>\n",
       "      <td>Windows Desktop</td>\n",
       "      <td>IE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>czqhjk3yfe</td>\n",
       "      <td>2014-07-01</td>\n",
       "      <td>2014-07-01 00:03:05</td>\n",
       "      <td>NaT</td>\n",
       "      <td>-unknown-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>direct</td>\n",
       "      <td>direct</td>\n",
       "      <td>untracked</td>\n",
       "      <td>Web</td>\n",
       "      <td>Mac Desktop</td>\n",
       "      <td>Safari</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id date_account_created timestamp_first_active date_first_booking  \\\n",
       "0  5uwns89zht           2014-07-01    2014-07-01 00:00:06                NaT   \n",
       "1  jtl0dijy2j           2014-07-01    2014-07-01 00:00:51                NaT   \n",
       "2  xx0ulgorjt           2014-07-01    2014-07-01 00:01:48                NaT   \n",
       "3  6c6puo6ix0           2014-07-01    2014-07-01 00:02:15                NaT   \n",
       "4  czqhjk3yfe           2014-07-01    2014-07-01 00:03:05                NaT   \n",
       "\n",
       "      gender   age signup_method  signup_flow language affiliate_channel  \\\n",
       "0     FEMALE  35.0      facebook            0       en            direct   \n",
       "1  -unknown-   NaN         basic            0       en            direct   \n",
       "2  -unknown-   NaN         basic            0       en            direct   \n",
       "3  -unknown-   NaN         basic            0       en            direct   \n",
       "4  -unknown-   NaN         basic            0       en            direct   \n",
       "\n",
       "  affiliate_provider first_affiliate_tracked signup_app first_device_type  \\\n",
       "0             direct               untracked      Moweb            iPhone   \n",
       "1             direct               untracked      Moweb            iPhone   \n",
       "2             direct                  linked        Web   Windows Desktop   \n",
       "3             direct                  linked        Web   Windows Desktop   \n",
       "4             direct               untracked        Web       Mac Desktop   \n",
       "\n",
       "   first_browser  \n",
       "0  Mobile Safari  \n",
       "1  Mobile Safari  \n",
       "2         Chrome  \n",
       "3             IE  \n",
       "4         Safari  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_user_features(train, test):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    from sklearn.feature_extraction import DictVectorizer\n",
    "    import scipy.sparse as sp\n",
    "    #encoding country destinations in train dataset\n",
    "    outcome = train['country_destination']\n",
    "    labels = outcome.values\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(labels)\n",
    "    train = train.drop(['country_destination'], axis=1)\n",
    "\n",
    "    #storing user ids in test set\n",
    "    id_test = test['id']\n",
    "\n",
    "    #appending test to train and dropping date first booking which is redundant\n",
    "    data = pd.concat((train, test), axis=0, ignore_index=True)\n",
    "    data = data.drop(['date_first_booking'], axis=1)\n",
    "\n",
    "    #extracting features from date_account_created\n",
    "    data['dac_year'] = data['date_account_created'].apply(lambda x: x.year)\n",
    "    data['dac_month'] = data['date_account_created'].apply(lambda x: x.month)\n",
    "    data['dac_weekday'] = data['date_account_created'].apply(lambda x: x.weekday())\n",
    "    data = data.drop(['date_account_created'], axis=1)\n",
    "\n",
    "    #extracting features from timestamp_first_active\n",
    "    data['tfa_year'] = data['timestamp_first_active'].apply(lambda x: x.year)\n",
    "    data['tfa_month'] = data['timestamp_first_active'].apply(lambda x: x.month)\n",
    "    data['tfa_weekday'] = data['timestamp_first_active'].apply(lambda x: x.weekday())\n",
    "    data = data.drop(['timestamp_first_active'], axis=1)\n",
    "\n",
    "    #filling age nan with age median\n",
    "    data.age = data['age'].fillna(data['age'].median())\n",
    "\n",
    "    #group age column\n",
    "    bins = list(np.arange(15, 85, 5))\n",
    "    bins.insert(0,0)\n",
    "    bins.append(int(max(data['age'])))\n",
    "    group_names = ['<15', '15-20', '20-25', '25-30', '30-35', '35-40', '40-45', '45-50',\n",
    "                   '50-55', '55-60', '60-65', '65-70', '70-75', '75-80', '>80']\n",
    "    data['age_bucket'] = pd.cut(data['age'], bins, labels=group_names)\n",
    "\n",
    "    #cleaning gender column and filling nan in all dataframe with 'unknown'\n",
    "    data['gender'] = data['gender'].replace('-unknown-','unknown')\n",
    "    data.ix[:, data.columns != 'age_bucket'] = data.ix[:, data.columns != 'age_bucket'].fillna('unknown')\n",
    "\n",
    "    #generating dummy variables in top of categorical columns\n",
    "    dummified = ['gender', 'signup_method', 'signup_flow', 'language', 'affiliate_channel', 'affiliate_provider', 'first_affiliate_tracked', 'signup_app', 'first_device_type', 'first_browser','age_bucket']\n",
    "    for f in dummified:\n",
    "        dummies = pd.get_dummies(data[f], prefix=f)\n",
    "        data = data.drop([f], axis=1)\n",
    "        data = pd.concat((data, dummies), axis=1)\n",
    "\n",
    "    return data[:train.shape[0]], data[train.shape[0]:], y, le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_sessions_features(data, df_sessions):\n",
    "    from sklearn.feature_extraction import DictVectorizer\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    from sklearn.feature_extraction import DictVectorizer\n",
    "    import scipy.sparse as sp\n",
    "    \n",
    "    # Drop row with nan values from the \"user_id\" column as they're useless\n",
    "    df_sessions = df_sessions.dropna(subset=[\"user_id\"])\n",
    "\n",
    "    # Frequency of devices - by user\n",
    "    device_freq = df_sessions.groupby('user_id').device_type.value_counts()\n",
    "    \n",
    "    # Frequency of actions taken - by user\n",
    "    action_freq = df_sessions.groupby('user_id').action.value_counts()\n",
    "\n",
    "    # Total list of users\n",
    "    users = data['id'].values\n",
    "    def feature_dict(df):\n",
    "        f_dict = dict(list(df.groupby(level='user_id')))\n",
    "        res = {}\n",
    "        for k, v in f_dict.items():\n",
    "            v.index = v.index.droplevel('user_id')\n",
    "            res[k] = v.to_dict()\n",
    "        return res\n",
    "\n",
    "    # Make a dictionary with the frequencies { 'user_id' : {\"IPhone\": 2, \"Windows\": 1}}\n",
    "    action_dict = feature_dict(action_freq)\n",
    "    device_dict = feature_dict(device_freq)\n",
    "\n",
    "    # Transform to a list of dictionaries\n",
    "    action_rows = [action_dict.get(k, {}) for k in users]\n",
    "    device_rows = [device_dict.get(k, {}) for k in users]\n",
    "\n",
    "    device_transf = DictVectorizer()\n",
    "    tf = device_transf.fit_transform(device_rows)\n",
    "\n",
    "    action_transf = DictVectorizer()\n",
    "    tf2 = action_transf.fit_transform(action_rows)\n",
    "\n",
    "    # Concatenate the two datasets\n",
    "    # Those are row vectors with the frequencies of both device and actions [0, 0, 0, 2, 0, 1, ...]\n",
    "    features = sp.hstack([tf, tf2])\n",
    "\n",
    "    # We create a dataframe with the new features and we write it to disk\n",
    "    df_sess_features = pd.DataFrame(features.todense())\n",
    "    \n",
    "    df_sess_features['id'] = users\n",
    "\n",
    "    #left joining data and sessions on user_id\n",
    "    final = pd.merge(data, df_sess_features, how='left', left_on='id', right_on='id')\n",
    "    final.ix[:, final.columns != 'age_bucket'].fillna(-1, inplace=True)\n",
    "\n",
    "\n",
    "    final.drop(['id'], axis=1, inplace=True)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SS\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:46: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate_ix\n"
     ]
    }
   ],
   "source": [
    "train, test, y, le = transform_user_features(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SS\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:55: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate_ix\n"
     ]
    }
   ],
   "source": [
    "data = pd.concat((train, test), axis=0, ignore_index=True)\n",
    "final = transform_sessions_features(data, df_sessions)\n",
    "\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = final.ix[:train.shape[0]-1]\n",
    "X_test = final.ix[train.shape[0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#assert train.shape[0] == y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(213451, 549)\n",
      "(62096, 549)\n",
      "(213451,)\n"
     ]
    }
   ],
   "source": [
    "#assert X_train.shape[0] == train.shape[0]\n",
    "#assert X_train.shape[0] == y.shape[0]\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "def bagging_prediction(X_train, y_train, X_test, \n",
    "                       n_estimators=100, \n",
    "                       max_samples=0.1, \n",
    "                       max_features=1.0, \n",
    "                       random_state=None):\n",
    "\n",
    "#    unimportant_features = np.load(\"unimportant_features.npy\")\n",
    "    bagg = BaggingClassifier(random_state=random_state, \n",
    "                             n_estimators=n_estimators, \n",
    "                             max_samples=max_samples, \n",
    "                             max_features=max_features)\n",
    "    bagg.fit(X_train, y_train)\n",
    "    return bagg.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "probs = []\n",
    "for i in range(3):\n",
    "    p = bagging_prediction(X_train, y, \n",
    "                           X_test,\n",
    "                           n_estimators=100,\n",
    "                           random_state=i)\n",
    "    probs.append(p)\n",
    "\n",
    "# We take the average\n",
    "avg_probs = sum(probs)/len(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.2       ,  0.04      ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.05333333,  0.00333333],\n",
       "       [ 0.        ,  0.00666667,  0.00333333, ...,  0.        ,\n",
       "         0.05333333,  0.01      ],\n",
       "       ..., \n",
       "       [ 0.        ,  0.00666667,  0.00333333, ...,  0.        ,\n",
       "         0.04666667,  0.01666667],\n",
       "       [ 0.        ,  0.00333333,  0.        , ...,  0.        ,\n",
       "         0.04666667,  0.01666667],\n",
       "       [ 0.00333333,  0.01      ,  0.00666667, ...,  0.        ,\n",
       "         0.3       ,  0.03333333]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = avg_probs\n",
    "ids = []  #list of ids\n",
    "cts = []  #list of countries\n",
    "id_test = pretest['id'].values\n",
    "for i in range(len(id_test)):\n",
    "    idx = id_test[i]\n",
    "    ids += [idx] * 5\n",
    "    cts += le.inverse_transform(np.argsort(y_pred[i])[::-1])[:5].tolist()\n",
    "\n",
    "#Submission\n",
    "sub = pd.DataFrame(np.column_stack((ids, cts)), columns=['id', 'country'])\n",
    "sub.to_csv('sub.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This solution has score in the Kaggle Leaderboard of 0.87656 (corresponding to position 336 of 1462 participants)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
